{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312558ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from transformers import *\n",
    "import numpy as np\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eaa8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "for index in range(n_gpu):\n",
    "    print(torch.cuda.get_device_name(index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd03649",
   "metadata": {},
   "source": [
    "## Load Data (Dataframes / Dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b2663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6138942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv') \n",
    "df = df.drop(labels=['abstract'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc660c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.read_csv('data/dev.csv') \n",
    "df_dev = df_dev.drop(labels=['abstract'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2e7a98-56a6-4a6a-8bd4-4ec805a7ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/test.csv') \n",
    "df_test = df_test.drop(labels=['abstract'], axis=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d36905",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = df.columns.to_list()\n",
    "num_labels = len(label_cols)\n",
    "bs = 8\n",
    "max_length = 512\n",
    "lambda_reg = 0.2\n",
    "bert_version = \"uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd2620",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.load(f'dataloaders/train_data_loader-{bs}-{max_length}')\n",
    "validation_dataloader = torch.load(f'dataloaders/validation_data_loader-{bs}-{max_length}')\n",
    "test_dataloader = torch.load(f'dataloaders/test_data_loader-{bs}-{max_length}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc3fb90",
   "metadata": {},
   "source": [
    "## Target Probabilities Tensor Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9820c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df.astype(bool).sum(axis=0).to_dict()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4597eee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_dev = df_dev.astype(bool).sum(axis=0).to_dict()\n",
    "print(counts_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217acdd8-cc84-49b2-b2dc-e8b78444b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_test = df_test.astype(bool).sum(axis=0).to_dict()\n",
    "print(counts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dab148",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_co_occurrence_matrix(counts: dict, dataframe):\n",
    "    columns = list(counts.keys())\n",
    "    target_prob = []\n",
    "    for column_1 in tqdm(columns, desc=\"Labels\", leave=True, position=0):\n",
    "        temp_list = []\n",
    "        for column_2 in columns:\n",
    "            count = len(dataframe[(dataframe[column_1] == 1) & (dataframe[column_2] == 1)])\n",
    "            freq = count / counts[column_1] if counts[column_1] else 0\n",
    "            temp_list.append(freq)\n",
    "            \n",
    "        target_prob.append(temp_list)\n",
    "        \n",
    "    target_prob = torch.tensor(target_prob, dtype=torch.float32)\n",
    "    target_prob = target_prob \n",
    "    return target_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfadd98f-abd5-4a35-a237-d31a5cb48255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(x1, x2, dim=1, eps=1e-8): \n",
    "    # calculate the dot product of matrix with itself\n",
    "    dot_product = torch.matmul(x1, x2.t())\n",
    "\n",
    "    # calculate the L2 norm of each line\n",
    "    x1_norm = x1.norm(dim=dim, keepdim=True) + eps\n",
    "    x2_norm = x2.norm(dim=dim, keepdim=True) + eps\n",
    "\n",
    "    # calculate the cosine similarity\n",
    "    cosine_similarity_matrix = dot_product / (x1_norm * x2_norm.t())\n",
    "    \n",
    "    return cosine_similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83391360",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "co_occurrence_matrix = make_co_occurrence_matrix(counts=counts, dataframe=df)\n",
    "co_occurrence_matrix = co_occurrence_matrix.to(device)\n",
    "label_sim = cos_sim(co_occurrence_matrix, co_occurrence_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "co_mat = co_occurrence_matrix[:8, :8]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = torch.tensor([0.9, 0.9, 0.1, 0, 0, 0, 0, 0.1], dtype=torch.float32)\n",
    "y = y.to(device)\n",
    "sim = cos_sim(y.unsqueeze(dim=0), co_mat)\n",
    "dsim = 1 - sim"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0a9cfa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "co_occurrence_matrix_dev = make_co_occurrence_matrix(counts=counts_dev, dataframe=df_dev)\n",
    "co_occurrence_matrix_dev = co_occurrence_matrix_dev.to(device)\n",
    "label_sim_dev = cos_sim(co_occurrence_matrix_dev, co_occurrence_matrix_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a7bd8-1e42-4a3d-9d4e-a20850aafc7e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "co_occurrence_matrix_test = make_co_occurrence_matrix(counts=counts_test, dataframe=df_test)\n",
    "co_occurrence_matrix_test = co_occurrence_matrix_test.to(device)\n",
    "label_sim_test = cos_sim(co_occurrence_matrix_test, co_occurrence_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f25d692",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': train_dataloader,\n",
    "    'dev': validation_dataloader,\n",
    "    'test': test_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eca52b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_label_sim = {\n",
    "    'train': label_sim,\n",
    "    'dev': label_sim_dev,\n",
    "    'test': label_sim_test\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9066b3",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1468a5",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e6b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd41f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(true_bools, pred_bools):\n",
    "    clf_report_optimized = classification_report(true_bools, pred_bools, target_names=label_cols, digits=5, zero_division=0, output_dict=True)\n",
    "    micro_avg = clf_report_optimized['micro avg']\n",
    "    f1 = f1_score(true_bools, pred_bools,average='micro')*100\n",
    "    acc = accuracy_score(true_bools, pred_bools)*100\n",
    "    precision = micro_avg['precision']*100\n",
    "    recall = micro_avg['recall']*100\n",
    "    \n",
    "    return f1, acc, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5429d2e4",
   "metadata": {},
   "source": [
    "### Preparing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5c41f2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(f\"bert-base-{bert_version}\", num_labels=num_labels)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34ea566",
   "metadata": {},
   "source": [
    "### Loss function and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa4b8f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setting custom optimization parameters. You may implement a scheduler here as well.\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "\n",
    "\n",
    "# exclude the last layer parameter from optimizer\n",
    "optimizer_grouped_parameters_classification = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89791ab0-98db-45ba-b26b-ba54b1e4ad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import _Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfbd4f8-a591-4f40-800f-f83a5c9d75cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep_reg_lossfn(preds, label_similarities, lambda_reg, dim=1):\n",
    "    lambda_reg = torch.tensor(lambda_reg)\n",
    "    preds = preds / torch.norm(preds, dim=dim, keepdim=True)\n",
    "    cosine_dissim = 1 - cos_sim(preds, label_similarities, dim=dim)\n",
    "    cosine_dissim = cosine_dissim.unsqueeze(dim=1)\n",
    "    preds = preds.unsqueeze(dim=1).transpose(dim0=1, dim1=2)\n",
    "\n",
    "    reg_loss = torch.bmm(cosine_dissim, preds).squeeze(dim=1)\n",
    "    reg_loss = torch.mean(reg_loss)\n",
    "    return lambda_reg * reg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2ffa31-44a2-48d9-b82d-ac86fff1ebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepRegLoss(_Loss):\n",
    "    def __init__(self, lambda_reg: float = 0.1) -> None:\n",
    "        super(DepRegLoss, self).__init__(lambda_reg)\n",
    "        self.lambda_reg = lambda_reg\n",
    "\n",
    "    def forward(self, preds: torch.Tensor, label_sim: torch.Tensor, dim: int = 1) -> torch.Tensor:\n",
    "        return dep_reg_lossfn(preds, label_sim, lambda_reg=self.lambda_reg, dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfc1d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_classification = torch.optim.AdamW(optimizer_grouped_parameters_classification, lr=2e-5)\n",
    "classification_criterion = torch.nn.BCELoss()\n",
    "dependency_reg_loss_criterion = DepRegLoss(lambda_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b576f41",
   "metadata": {},
   "source": [
    "### Logging and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b920d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f\"bert+DepRegLoss-{lambda_reg}\"\n",
    "dataset_name = \"AAPD\"\n",
    "epochs = 32\n",
    "threshold = 0.5\n",
    "metrics = {\"Epoch\": None, \"Train BCE Loss\": None, \"Train Reg Loss\": None, \"Train micro-F1\": None, \"Dev BCE Loss\": None, \"Dev Reg Loss\": None, \"Dev micro-F1\": None, \"Test BCE Loss\": None, \"Test Reg Loss\": None, \"Test micro-F1\": None, \"Duration\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f0e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"epochs\": epochs, \"batch_size\": bs, \"seq_max_length\": max_length,\n",
    "          \"lr_cls\": 2e-5, \"lambda_reg\": lambda_reg, \"bert version\": bert_version,\n",
    "         \"cls_thd\": threshold, \"optimizer\": \"AdamW\", \"wd\": 0.01, \"model_name\": model_name, \"dataset\": dataset_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca7225",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_val_f1 = -1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ad82b1",
   "metadata": {},
   "source": [
    "### Train !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6977ad",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for epoch_num in trange(config.get('epochs'), desc=\"Epoch\", position=0):\n",
    "    metrics['Epoch'] = str(epoch_num+1)\n",
    "    epoch_since = time.time()\n",
    "    for phase in tqdm(['train', 'dev'], leave=False, desc='Phases', position=1):\n",
    "\n",
    "        # Tracking variables\n",
    "        true_labels,pred_labels = [], [] # for metrics\n",
    "        epoch_loss, cls_loss = 0, 0 # running losses\n",
    "        epoch_steps = 0\n",
    "        \n",
    "        if phase == 'train': \n",
    "            model.train()\n",
    "            \n",
    "        if phase == 'dev':\n",
    "            model.eval()\n",
    "            \n",
    "        for step, batch in enumerate(tqdm(dataloaders[phase], leave=False, desc=f\"{phase.capitalize()} Dataloader\", position=2)):\n",
    "\n",
    "            # Add batch to GPU\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Unpack the inputs from our dataloader\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "            # Forward pass for multilabel classification\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(b_input_ids, attention_mask=b_input_mask)[0]\n",
    "                classification_logits = outputs\n",
    "                classification_logits = torch.sigmoid(classification_logits)\n",
    "                \n",
    "            del b_input_ids, b_input_mask, outputs\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            #loss calculation\n",
    "            bce_loss = classification_criterion(classification_logits, b_labels.type_as(classification_logits))\n",
    "            dep_reg_loss = dependency_reg_loss_criterion(classification_logits, target_label_sim[phase])\n",
    "            loss = bce_loss\n",
    "            \n",
    "            if phase == 'train': \n",
    "\n",
    "                # Clear out the gradients \n",
    "                optimizer_classification.zero_grad()\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                    \n",
    "                # Update parameters and take a step using the computed gradient\n",
    "                optimizer_classification.step()\n",
    "\n",
    "            # Update tracking variables\n",
    "            cls_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "            \n",
    "            # Update Epoch Metrics\n",
    "            pred_label = classification_logits.detach().to('cpu').numpy()\n",
    "            b_labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "            true_labels.append(b_labels)\n",
    "            pred_labels.append(pred_label)\n",
    "            \n",
    "\n",
    "\n",
    "        # Get Epoch Metrics\n",
    "        # Flatten outputs\n",
    "        pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "        true_labels = [item for sublist in true_labels for item in sublist]\n",
    "        \n",
    "        true_bools = true_labels \n",
    "        pred_bools = [pl>config.get('threshold') for pl in pred_labels]\n",
    "        f1_accuracy, flat_accuracy, precision, recall = get_metrics(true_bools, pred_bools)\n",
    "        \n",
    "        # Get Epoch Losses\n",
    "        cls_loss = cls_loss/epoch_steps\n",
    "        \n",
    "\n",
    "        # Log Epoch Metrics\n",
    "        metrics = {f'{phase.capitalize()} BCE Loss': f\"{bce_loss:.6f}\",\n",
    "                   f'{phase.capitalize()} Reg Loss': f\"{dep_reg_loss:.4f}\",\n",
    "                   f'{phase.capitalize()} micro-F1': f\"{f1_accuracy.item():.3f}\"}\n",
    "\n",
    "\n",
    "        # Save model if valid performances are better\n",
    "        if phase == 'val':\n",
    "            if  f1_accuracy > best_val_f1:\n",
    "                best_val_f1 = f1_accuracy\n",
    "                torch.save(model.state_dict(), 'state_dicts/best_'+ config.get('model_name') +'.pt')\n",
    "                \n",
    "        # log metrics into table and show it  \n",
    "        if phase == 'val':\n",
    "            epoch_time_elapsed = time.time() - epoch_since\n",
    "            metrics['Duration'] = time.strftime(\"%H:%M:%S\", time.gmtime(epoch_time_elapsed))\n",
    "\n",
    "            print(metrics)\n",
    "\n",
    "# save last model\n",
    "torch.save(model.state_dict(), 'state_dicts/last_'+ config.get('model_name') +'.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
